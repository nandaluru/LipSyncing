{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "13dHGlIfjgAEEHhabpKqwpy575gOgfo7q",
      "authorship_tag": "ABX9TyNW1wk1kj3P+l3E9TGsGWzW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nandaluru/LipSyncing/blob/main/LipSyncing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Mount Google Drive**\n",
        "In this cell, we will mount Google Drive to access files in the Colab environment.\n"
      ],
      "metadata": {
        "id": "YmFg9pCZSsMK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8jYh5CaivG_",
        "outputId": "9904dd55-2059-4d6e-9577-6ae4f9ae77d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6fQyW57STPF",
        "outputId": "379513dd-edb5-46ae-ab42-9b47f2a62a42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Clone Wav2Lip Repository from GitHub**\n",
        "\n",
        "In this cell, we will clone the Wav2Lip repository from GitHub. This repository contains the source code and related files for the Wav2Lip project.\n"
      ],
      "metadata": {
        "id": "9ZPEf0q0TWih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Rudrabha/Wav2Lip.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2v8DVFLTeCE",
        "outputId": "5e3f6943-a17c-44ff-a687-b14d721e5ef1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Wav2Lip' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Setup Google Drive**\n",
        "\n",
        "1. **Create Folders:**\n",
        "    - In Google Drive, make a folder named `LipSync` in MyDrive.\n",
        "    - Create another folder called `model_weights`.\n",
        "\n",
        "2. **Upload Files:**\n",
        "    - Upload `input-video.mp4` and `input-audio.wav` to `LipSync`.\n",
        "    - Download pretrained model weights from [Wav2Lip GitHub](https://github.com/Rudrabha/Wav2Lip#getting-the-weights) and upload them to `model_weights`.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ukHLC-QyUan_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Contents of /content/drive/MyDrive/LipSync**\n",
        "\n",
        "In this cell, we will list the contents of the `LipSync` directory in your Google Drive.\n"
      ],
      "metadata": {
        "id": "tRQpd_uMVuC2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/LipSync"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAdxJjclWbXJ",
        "outputId": "57ec8c0f-2f23-4f6d-9af4-9ff9efab69c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input-audio.wav  input-video.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Copy Pretrained Model to Wav2Lip Checkpoints**\n",
        "\n",
        "In this cell, we copy the pretrained model (`wav2lip_gan.pth`) from the Google Drive folder to the `checkpoints` directory in the Wav2Lip project.\n"
      ],
      "metadata": {
        "id": "uZrQD2gSYCyu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -ri \"/content/drive/MyDrive/model_weights/wav2lip_gan.pth\" /content/Wav2Lip/checkpoints/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZ_xgYSYYMgd",
        "outputId": "e4fb4e41-e4d5-4bd2-aa88-c5b4253fc561"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: overwrite '/content/Wav2Lip/checkpoints/wav2lip_gan.pth'? y\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Install Wav2Lip Dependencies**\n",
        "\n",
        "In this cell, we install the required Python packages listed in the `requirements.txt` file.\n"
      ],
      "metadata": {
        "id": "nuAgsZ_BW-mq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd Wav2Lip && pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOnA1expWsmJ",
        "outputId": "6a00c9ec-e1bc-4e8e-9c2a-6289a9b5e0e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting librosa==0.7.0 (from -r requirements.txt (line 1))\n",
            "  Using cached librosa-0.7.0.tar.gz (1.6 MB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting numpy==1.17.1 (from -r requirements.txt (line 2))\n",
            "  Using cached numpy-1.17.1.zip (6.5 MB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: opencv-contrib-python>=4.2.0.34 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (4.8.0.76)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement opencv-python==4.1.0.25 (from versions: 3.4.0.14, 3.4.10.37, 3.4.11.39, 3.4.11.41, 3.4.11.43, 3.4.11.45, 3.4.13.47, 3.4.15.55, 3.4.16.57, 3.4.16.59, 3.4.17.61, 3.4.17.63, 3.4.18.65, 4.3.0.38, 4.4.0.40, 4.4.0.42, 4.4.0.44, 4.4.0.46, 4.5.1.48, 4.5.3.56, 4.5.4.58, 4.5.4.60, 4.5.5.62, 4.5.5.64, 4.6.0.66, 4.7.0.68, 4.7.0.72, 4.8.0.74, 4.8.0.76, 4.8.1.78, 4.9.0.80)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for opencv-python==4.1.0.25\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa==0.8.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmazUjwOYqSp",
        "outputId": "45d2669d-0fb7-44d8-bc9d-b5741d5510b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: librosa==0.8.0 in /usr/local/lib/python3.10/dist-packages (0.8.0)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.8.0) (3.0.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.8.0) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.8.0) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.8.0) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa==0.8.0) (1.3.2)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.8.0) (4.4.2)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from librosa==0.8.0) (0.4.2)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.8.0) (0.58.1)\n",
            "Requirement already satisfied: soundfile>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.8.0) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.8.0) (1.8.0)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.43.0->librosa==0.8.0) (0.41.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa==0.8.0) (4.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa==0.8.0) (23.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa==0.8.0) (2.31.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa==0.8.0) (3.2.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.9.0->librosa==0.8.0) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.9.0->librosa==0.8.0) (2.21)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.0) (2023.11.17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Download Face Detection Model (s3fd.pth)**\n",
        "\n",
        "In this cell, we download the face detection model (`s3fd.pth`) from [Adrian Bulat's website](https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth) and save it in the appropriate directory within the Wav2Lip project.\n"
      ],
      "metadata": {
        "id": "VJv-vbO_ZV4R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget \"https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\" -O \"Wav2Lip/face_detection/detection/sfd/s3fd.pth\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02UkIEkbZoxV",
        "outputId": "9689a67a-7a3b-4d98-fa44-98f92fe477c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-31 15:46:40--  https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\n",
            "Resolving www.adrianbulat.com (www.adrianbulat.com)... 45.136.29.207\n",
            "Connecting to www.adrianbulat.com (www.adrianbulat.com)|45.136.29.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 89843225 (86M) [application/octet-stream]\n",
            "Saving to: ‘Wav2Lip/face_detection/detection/sfd/s3fd.pth’\n",
            "\n",
            "Wav2Lip/face_detect 100%[===================>]  85.68M  20.4MB/s    in 4.9s    \n",
            "\n",
            "2023-12-31 15:46:45 (17.6 MB/s) - ‘Wav2Lip/face_detection/detection/sfd/s3fd.pth’ saved [89843225/89843225]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Copy Input Files to Sample Data**\n",
        "\n",
        "In this cell, we copy the input video (`input-video.mp4`) and input audio (`input-audio.wav`) from the Google Drive directory to the `sample_data` directory.\n"
      ],
      "metadata": {
        "id": "tt1QidnEaNnP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp \"/content/drive/MyDrive/LipSync/input-video.mp4\" \"/content/drive/MyDrive/LipSync/input-audio.wav\" sample_data/\n",
        "!ls sample_data/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_iKJ4i0afg1",
        "outputId": "5b96a043-84c9-4df2-c09f-a43e563b70f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "anscombe.json\t\t     california_housing_train.csv  input-video.mp4  mnist_train_small.csv\n",
            "california_housing_test.csv  input-audio.wav\t\t   mnist_test.csv   README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Run Wav2Lip Inference**\n",
        "\n",
        "In this cell, we run the Wav2Lip inference script (`inference.py`) with the specified checkpoint path, input video, and audio files. The initial inference is performed without resizing, and later, a resized version is attempted with a specified resize factor.\n",
        "\n"
      ],
      "metadata": {
        "id": "9-buAYBPbZ9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd Wav2Lip && python inference.py --checkpoint_path checkpoints/wav2lip_gan.pth --face \"/content/drive/MyDrive/LipSync/input-video.mp4\" --audio \"/content/sample_data/input-audio.wav\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQ-HTIJIb9qW",
        "outputId": "d1ce161b-e90f-4f12-96a3-60f2fc07bd3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu for inference.\n",
            "Reading video frames...\n",
            "Number of frames available for inference: 796\n",
            "(80, 5386)\n",
            "Length of mel chunks: 1680\n",
            "  0% 0/14 [00:00<?, ?it/s]\n",
            "  0% 0/50 [00:00<?, ?it/s]\u001b[A^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Variations to try**\n",
        "\n",
        "- Use more padding to include the chin region.\n",
        "\n",
        "- Use resize_factor to reduce the video resolution, as there is a change you might get better results for lower resolution videos. Why? Because the model was trained on low resolution faces."
      ],
      "metadata": {
        "id": "WbNFvn3Ihc3K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd Wav2Lip && python inference.py --checkpoint_path checkpoints/wav2lip_gan.pth --face \"../sample_data/input-video.mp4\" --audio \"../sample_data/input-audio.wav\" --resize_factor 3 --pad 2 5 0 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZYG8pTKcTjP",
        "outputId": "120df1b3-ec67-4f16-bcca-190d4cf3df01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu for inference.\n",
            "Reading video frames...\n",
            "Number of frames available for inference: 796\n",
            "(80, 5386)\n",
            "Length of mel chunks: 1680\n",
            "  0% 0/14 [00:00<?, ?it/s]\n",
            "  0% 0/50 [00:00<?, ?it/s]\u001b[A\n",
            "  2% 1/50 [00:22<18:40, 22.86s/it]\u001b[A\n",
            "  4% 2/50 [00:44<17:49, 22.29s/it]\u001b[A\n",
            "  6% 3/50 [01:06<17:24, 22.22s/it]\u001b[A\n",
            "  8% 4/50 [01:28<16:57, 22.11s/it]\u001b[A\n",
            " 10% 5/50 [01:50<16:32, 22.07s/it]\u001b[A\n",
            " 12% 6/50 [02:13<16:14, 22.16s/it]\u001b[A\n",
            " 14% 7/50 [02:34<15:46, 22.01s/it]\u001b[A\n",
            " 16% 8/50 [02:57<15:28, 22.10s/it]\u001b[A\n",
            " 18% 9/50 [03:20<15:27, 22.63s/it]\u001b[A\n",
            " 20% 10/50 [03:46<15:43, 23.58s/it]\u001b[A\n",
            " 22% 11/50 [04:07<14:51, 22.85s/it]\u001b[A\n",
            " 24% 12/50 [04:30<14:29, 22.88s/it]\u001b[A\n",
            " 26% 13/50 [04:51<13:47, 22.37s/it]\u001b[A\n",
            " 28% 14/50 [05:14<13:30, 22.52s/it]\u001b[A\n",
            " 30% 15/50 [05:36<12:53, 22.11s/it]\u001b[A\n",
            " 32% 16/50 [05:58<12:39, 22.35s/it]\u001b[A\n",
            " 34% 17/50 [06:20<12:07, 22.04s/it]\u001b[A\n",
            " 36% 18/50 [06:43<11:53, 22.31s/it]\u001b[A\n",
            " 38% 19/50 [07:04<11:21, 21.97s/it]\u001b[A\n",
            " 40% 20/50 [07:27<11:07, 22.25s/it]\u001b[A\n",
            " 42% 21/50 [07:48<10:35, 21.92s/it]\u001b[A\n",
            " 44% 22/50 [08:11<10:23, 22.26s/it]\u001b[A\n",
            " 46% 23/50 [08:32<09:52, 21.96s/it]\u001b[A\n",
            " 48% 24/50 [08:55<09:38, 22.23s/it]\u001b[A\n",
            " 50% 25/50 [09:16<09:09, 21.97s/it]\u001b[A\n",
            " 52% 26/50 [09:46<09:38, 24.10s/it]\u001b[A\n",
            " 54% 27/50 [10:10<09:16, 24.19s/it]\u001b[A\n",
            " 56% 28/50 [10:31<08:33, 23.33s/it]\u001b[A\n",
            " 58% 29/50 [10:54<08:08, 23.26s/it]\u001b[A\n",
            " 60% 30/50 [11:16<07:33, 22.66s/it]\u001b[A\n",
            " 62% 31/50 [11:39<07:12, 22.76s/it]\u001b[A\n",
            " 64% 32/50 [12:00<06:42, 22.35s/it]\u001b[A\n",
            " 66% 33/50 [12:23<06:23, 22.55s/it]\u001b[A\n",
            " 68% 34/50 [12:44<05:55, 22.21s/it]\u001b[A\n",
            " 70% 35/50 [13:07<05:35, 22.35s/it]\u001b[A\n",
            " 72% 36/50 [13:29<05:09, 22.11s/it]\u001b[A\n",
            " 74% 37/50 [13:51<04:48, 22.22s/it]\u001b[A\n",
            " 76% 38/50 [14:13<04:25, 22.16s/it]\u001b[A\n",
            " 78% 39/50 [14:38<04:11, 22.84s/it]\u001b[A\n",
            " 80% 40/50 [15:01<03:48, 22.88s/it]\u001b[A\n",
            " 82% 41/50 [15:22<03:22, 22.48s/it]\u001b[A\n",
            " 84% 42/50 [15:45<03:00, 22.61s/it]\u001b[A\n",
            " 86% 43/50 [16:06<02:35, 22.22s/it]\u001b[A\n",
            " 88% 44/50 [16:29<02:14, 22.44s/it]\u001b[A\n",
            " 90% 45/50 [16:51<01:50, 22.08s/it]\u001b[A\n",
            " 92% 46/50 [17:14<01:29, 22.36s/it]\u001b[A\n",
            " 94% 47/50 [17:35<01:05, 22.00s/it]\u001b[A\n",
            " 96% 48/50 [17:58<00:44, 22.27s/it]\u001b[A\n",
            " 98% 49/50 [18:19<00:22, 22.04s/it]\u001b[A\n",
            "100% 50/50 [18:37<00:00, 22.34s/it]\n",
            "Load checkpoint from: checkpoints/wav2lip_gan.pth\n",
            "Model loaded\n",
            "100% 14/14 [24:40<00:00, 105.73s/it]\n",
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "\u001b[0;35m[mp3 @ 0x557f897b1240] \u001b[0m\u001b[0;33mEstimating duration from bitrate, this may be inaccurate\n",
            "\u001b[0mInput #0, mp3, from '../sample_data/input-audio.wav':\n",
            "  Duration: 00:01:07.32, start: 0.000000, bitrate: 96 kb/s\n",
            "  Stream #0:0: Audio: mp3, 44100 Hz, mono, fltp, 96 kb/s\n",
            "Input #1, avi, from 'temp/result.avi':\n",
            "  Metadata:\n",
            "    software        : Lavf59.27.100\n",
            "  Duration: 00:01:07.20, start: 0.000000, bitrate: 762 kb/s\n",
            "  Stream #1:0: Video: mpeg4 (Simple Profile) (DIVX / 0x58564944), yuv420p, 480x240 [SAR 1:1 DAR 2:1], 757 kb/s, 25 fps, 25 tbr, 25 tbn, 25 tbc\n",
            "Stream mapping:\n",
            "  Stream #1:0 -> #0:0 (mpeg4 (native) -> h264 (libx264))\n",
            "  Stream #0:0 -> #0:1 (mp3 (mp3float) -> aac (native))\n",
            "Press [q] to stop, [?] for help\n",
            "\u001b[1;36m[libx264 @ 0x557f89803100] \u001b[0m\u001b[0;33m-qscale is ignored, -crf is recommended.\n",
            "\u001b[0m\u001b[1;36m[libx264 @ 0x557f89803100] \u001b[0musing SAR=1/1\n",
            "\u001b[1;36m[libx264 @ 0x557f89803100] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
            "\u001b[1;36m[libx264 @ 0x557f89803100] \u001b[0mprofile High, level 2.1, 4:2:0, 8-bit\n",
            "\u001b[1;36m[libx264 @ 0x557f89803100] \u001b[0m264 - core 163 r3060 5db6aa6 - H.264/MPEG-4 AVC codec - Copyleft 2003-2021 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=3 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
            "Output #0, mp4, to 'results/result_voice.mp4':\n",
            "  Metadata:\n",
            "    encoder         : Lavf58.76.100\n",
            "  Stream #0:0: Video: h264 (avc1 / 0x31637661), yuv420p(progressive), 480x240 [SAR 1:1 DAR 2:1], q=2-31, 25 fps, 12800 tbn\n",
            "    Metadata:\n",
            "      encoder         : Lavc58.134.100 libx264\n",
            "    Side data:\n",
            "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
            "  Stream #0:1: Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, mono, fltp, 69 kb/s\n",
            "    Metadata:\n",
            "      encoder         : Lavc58.134.100 aac\n",
            "frame= 1680 fps=128 q=-1.0 Lsize=    2739kB time=00:01:07.31 bitrate= 333.3kbits/s speed=5.14x    \n",
            "video:2115kB audio:571kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 1.995845%\n",
            "\u001b[1;36m[libx264 @ 0x557f89803100] \u001b[0mframe I:8     Avg QP:17.86  size:  7557\n",
            "\u001b[1;36m[libx264 @ 0x557f89803100] \u001b[0mframe P:827   Avg QP:22.18  size:  1947\n",
            "\u001b[1;36m[libx264 @ 0x557f89803100] \u001b[0mframe B:845   Avg QP:26.90  size:   584\n",
            "\u001b[1;36m[libx264 @ 0x557f89803100] \u001b[0mconsecutive B-frames: 28.3% 10.6% 10.2% 51.0%\n",
            "\u001b[1;36m[libx264 @ 0x557f89803100] \u001b[0mmb I  I16..4: 18.6% 68.1% 13.2%\n",
            "\u001b[1;36m[libx264 @ 0x557f89803100] \u001b[0mmb P  I16..4:  1.4%  6.5%  0.5%  P16..4: 25.0% 12.3%  7.5%  0.0%  0.0%    skip:46.7%\n",
            "\u001b[1;36m[libx264 @ 0x557f89803100] \u001b[0mmb B  I16..4:  0.2%  1.4%  0.1%  B16..8: 31.2%  5.4%  1.4%  direct: 1.0%  skip:59.3%  L0:46.7% L1:43.6% BI: 9.7%\n",
            "\u001b[1;36m[libx264 @ 0x557f89803100] \u001b[0m8x8 transform intra:77.6% inter:60.3%\n",
            "\u001b[1;36m[libx264 @ 0x557f89803100] \u001b[0mcoded y,uvDC,uvAC intra: 37.5% 31.6% 7.9% inter: 9.9% 6.2% 0.2%\n",
            "\u001b[1;36m[libx264 @ 0x557f89803100] \u001b[0mi16 v,h,dc,p: 46% 14% 27% 13%\n",
            "\u001b[1;36m[libx264 @ 0x557f89803100] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 28% 14% 48%  2%  1%  2%  1%  1%  2%\n",
            "\u001b[1;36m[libx264 @ 0x557f89803100] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 25% 20% 15%  4%  7%  8% 10%  6%  5%\n",
            "\u001b[1;36m[libx264 @ 0x557f89803100] \u001b[0mi8c dc,h,v,p: 60% 15% 23%  2%\n",
            "\u001b[1;36m[libx264 @ 0x557f89803100] \u001b[0mWeighted P-Frames: Y:0.6% UV:0.0%\n",
            "\u001b[1;36m[libx264 @ 0x557f89803100] \u001b[0mref P L0: 70.5% 11.6% 12.7%  5.1%  0.1%\n",
            "\u001b[1;36m[libx264 @ 0x557f89803100] \u001b[0mref B L0: 85.6% 11.4%  3.0%\n",
            "\u001b[1;36m[libx264 @ 0x557f89803100] \u001b[0mref B L1: 96.3%  3.7%\n",
            "\u001b[1;36m[libx264 @ 0x557f89803100] \u001b[0mkb/s:257.71\n",
            "\u001b[1;36m[aac @ 0x557f898042c0] \u001b[0mQavg: 158.533\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **View the output video in content/Wav2Lip/results/**"
      ],
      "metadata": {
        "id": "M7mBxjzB52lH"
      }
    }
  ]
}